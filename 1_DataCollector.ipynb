{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# The Data Collector\n",
    "\n",
    "This notebook will be used to collect data to be used in the rest of the dashboard. Each\n",
    "cell will be a self-contained codebase to collect data for a single data point, and will\n",
    "correspond to a similar cell within The Dashboard UI notebook. Data persistence for these\n",
    "notebooks will be in locally-stored CSV files (that can be changed easily by updating a\n",
    "shared data persistence function), and the general execution flow will be as follows:\n",
    "\n",
    "## Check last import date\n",
    "Each data type and source will have a hard-coded Data Import Frequency variable, set by\n",
    "looking at historical update frequency for said data. Checking this against the last import\n",
    "date of the data in storage protects against unnecessary data pulls, network IO, and IP\n",
    "blocking from data sources.\n",
    "\n",
    "## Import data\n",
    "If our cell passes the last import date gate, then we append new data to our existing source\n",
    "in persistent storage.\n",
    "\n",
    "## Check for consistency\n",
    "Once data is imported, new data is checked against existing data to compare for consistency,\n",
    "outliers, and missing values. If inconsistencies or missing values are found, the import is\n",
    "flagged for human review.\n",
    "\n",
    "# Shared functions\n",
    "This cell contains functions to be used among all collectors, to minimize duplicated code.\n",
    "*Note*: this cell _must_ be initialized before running any collector cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# function that opens or creates CSV in persistent storage\n",
    "def file_opener(collector_type: str, collector_subtype: str, file_name: str) -> None:\n",
    "    import os\n",
    "\n",
    "    target_directory = os.path.join('data', 'output', collector_type, collector_subtype)\n",
    "    target_file = os.path.join(target_directory, file_name)\n",
    "\n",
    "    if os.path.exists(target_directory):\n",
    "        print('exists')\n",
    "    else:\n",
    "        os.\n",
    "\n",
    "# function that checks CSV date last updated\n",
    "def file_last_updated(file_name: str) -> str:\n",
    "    pass\n",
    "\n",
    "# stub function that connects to an API to collect data based on CSV last updated date\n",
    "def API_downloader(url:str, params: dict) -> None:\n",
    "    pass\n",
    "\n",
    "# stub function that scrapes website (if no API available) based on CSV last updated date\n",
    "def scraper_downloader(url: str, params: dict) -> None:\n",
    "    pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1.1 Geographic Data: Basemaps\n",
    "This consists of international, supranational, national, and province-level boundaries, as\n",
    "well as major cities. Data is meant to be used as base layers for other geospatial products.\n",
    "\n",
    "Data Import Frequency: n/a"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}